/*
Projeto: Leitor de Tela acessível — Protótipo completo (corrigido)
Stack: Electron + React + Tesseract.js (OCR) + Web Speech API (TTS)

Arquivos incluídos abaixo. Copie para uma pasta e execute:
1) npm install
2) npm run dev

Observações:
- Protótipo: ajuste de coordenadas, performance e permissões são necessários para produção.
- Para melhor qualidade de voz, integre Google Cloud TTS. Para OCR mais rápido/preciso, use Google/Azure Vision.
*/

//////////////////////// package.json ////////////////////////
{
  "name": "screen-reader-prototype",
  "version": "0.2.0",
  "main": "main.js",
  "scripts": {
    "dev": "electron .",
    "start": "electron ."
  },
  "dependencies": {
    "electron": "^26.0.0",
    "tesseract.js": "^4.0.2",
    "react": "^18.2.0",
    "react-dom": "^18.2.0"
  },
  "devDependencies": {
    "vite": "^5.0.0"
  }
}

//////////////////////// main.js ////////////////////////
const { app, BrowserWindow, desktopCapturer, ipcMain, screen } = require('electron')
const path = require('path')

function createWindow() {
  const win = new BrowserWindow({
    width: 1000,
    height: 700,
    webPreferences: {
      preload: path.join(__dirname, 'preload.js'),
      contextIsolation: true,
      nodeIntegration: false
    }
  })

  win.loadFile(path.join(__dirname, 'index.html'))
}

app.whenReady().then(() => {
  createWindow()
  app.on('activate', function () {
    if (BrowserWindow.getAllWindows().length === 0) createWindow()
  })
})

app.on('window-all-closed', function () {
  if (process.platform !== 'darwin') app.quit()
})

ipcMain.handle('get-sources', async () => {
  const sources = await desktopCapturer.getSources({ types: ['screen'] })
  return sources.map(s => ({ id: s.id, name: s.name }))
})

ipcMain.handle('get-cursor-point', () => {
  return screen.getCursorScreenPoint()
})

//////////////////////// preload.js ////////////////////////
const { contextBridge, ipcRenderer } = require('electron')

contextBridge.exposeInMainWorld('electronAPI', {
  getSources: () => ipcRenderer.invoke('get-sources'),
  getCursorPoint: () => ipcRenderer.invoke('get-cursor-point')
})

//////////////////////// index.html ////////////////////////
<!doctype html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Leitor de Tela — Protótipo</title>
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="./src/main.jsx"></script>
  </body>
</html>

//////////////////////// src/main.jsx ////////////////////////
import React from 'react'
import { createRoot } from 'react-dom/client'
import App from './App'
import './styles.css'

createRoot(document.getElementById('root')).render(<App />)

//////////////////////// src/App.jsx ////////////////////////
import React, { useEffect, useRef, useState } from 'react'
import Tesseract from 'tesseract.js'

export default function App() {
  const videoRef = useRef(null)
  const canvasRef = useRef(null)
  const [listening, setListening] = useState(false)
  const [ocrText, setOcrText] = useState('')
  const [cursorMode, setCursorMode] = useState(true)
  const lastSpokenRef = useRef('')
  const workerRef = useRef(null)

  useEffect(() => {
    let mounted = true
    ;(async () => {
      workerRef.current = Tesseract.createWorker({ logger: () => {} })
      await workerRef.current.load()
      await workerRef.current.loadLanguage('por')
      await workerRef.current.initialize('por')
    })()
    return () => {
      mounted = false
      if (workerRef.current) workerRef.current.terminate()
    }
  }, [])

  useEffect(() => {
    ;(async () => {
      try {
        const sources = await window.electronAPI.getSources()
        if (sources && sources.length > 0) {
          await startCapture(sources[0].id)
        }
      } catch (e) {
        console.error('getSources failed', e)
      }
    })()
  }, [])

  async function startCapture(id) {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: false,
        video: {
          mandatory: {
            chromeMediaSource: 'desktop',
            chromeMediaSourceId: id,
            minWidth: 800,
            maxWidth: 8000,
            minHeight: 600,
            maxHeight: 8000
          }
        }
      })
      videoRef.current.srcObject = stream
      await videoRef.current.play()
    } catch (err) {
      console.error('capture error', err)
    }
  }

  async function doFullOcr() {
    if (!canvasRef.current || !videoRef.current || !workerRef.current) return
    const ctx = canvasRef.current.getContext('2d')
    canvasRef.current.width = videoRef.current.videoWidth
    canvasRef.current.height = videoRef.current.videoHeight
    ctx.drawImage(videoRef.current, 0, 0)
    const dataUrl = canvasRef.current.toDataURL('image/png')
    const { data: { text } } = await workerRef.current.recognize(dataUrl)
    setOcrText(text)
    speakText(text)
  }

  async function doCursorOcrAndHint() {
    try {
      const pt = await window.electronAPI.getCursorPoint()
      if (!videoRef.current || !canvasRef.current || !workerRef.current) return
      const area = 300
      const ctx = canvasRef.current.getContext('2d')
      canvasRef.current.width = area
      canvasRef.current.height = area
      // NOTE: mapping cursor coordinates to video frame is simplified here
      ctx.drawImage(videoRef.current, pt.x - area / 2, pt.y - area / 2, area, area, 0, 0, area, area)
      const dataUrl = canvasRef.current.toDataURL('image/png')
      const { data: { text } } = await workerRef.current.recognize(dataUrl)
      const cleaned = text.replace(/\s+/g, ' ').trim()
      if (cleaned && cleaned !== lastSpokenRef.current) {
        lastSpokenRef.current = cleaned
        setOcrText(cleaned)
        speakText(cleaned + generateHint(cleaned))
      }
    } catch (e) {
      // ignore occasional capture errors
    }
  }

  function generateHint(text) {
    const lc = text.toLowerCase()
    if (lc.includes('botão') || lc.includes('clicar') || lc.includes('ok') || lc.includes('confirmar')) {
      return '. Dica: pressione Enter para ativar.'
    }
    if (lc.includes('link') || lc.includes('http')) {
      return '. Dica: mantenha o cursor e pressione Ctrl+Enter para abrir.'
    }
    return ''
  }

  function speakText(text) {
    if (!('speechSynthesis' in window)) return
    window.speechSynthesis.cancel()
    const ut = new SpeechSynthesisUtterance(text)
    ut.lang = 'pt-BR'
    ut.rate = 1
    window.speechSynthesis.speak(ut)
  }

  useEffect(() => {
    let interval
    if (listening && cursorMode) {
      interval = setInterval(() => {
        doCursorOcrAndHint().catch(() => {})
      }, 1500)
    }
    return () => clearInterval(interval)
  }, [listening, cursorMode])

  return (
    <div className="app-root">
      <h1>Leitor de Tela — Protótipo (Corrigido)</h1>

      <div className="controls">
        <button onClick={() => setListening(s => !s)}>
          {listening ? 'Parar leitura contínua' : 'Iniciar leitura contínua'}
        </button>

        <button onClick={() => setCursorMode(m => !m)}>
          Alternar modo ({cursorMode ? 'Cursor' : 'Tela completa'})
        </button>

        <button onClick={() => doFullOcr()}>Ler toda a tela agora</button>
      </div>

      <div className="detected">
        <h2>Texto detectado</h2>
        <div className="text-box">{ocrText || <i>(Nenhum texto detectado)</i>}</div>
      </div>

      <video ref={videoRef} style={{ display: 'none' }}></video>
      <canvas ref={canvasRef} style={{ display: 'none' }} />

      <div className="notes">
        <p>Notas: mapa de coordenadas é simplificado neste protótipo. Para precisão em múltiplos monitores/DPI, ajustar transformações de escala.</p>
      </div>
    </div>
  )
}

//////////////////////// src/styles.css ////////////////////////
body { font-family: Arial, Helvetica, sans-serif; margin: 0; padding: 0; }
.app-root { padding: 20px; }
.controls { display: flex; gap: 8px; margin-bottom: 16px; }
.controls button { padding: 8px 12px; border-radius: 6px; border: 1px solid #ccc; background: #f3f4f6; cursor: pointer; }
.controls button:hover { filter: brightness(0.98); }
.detected .text-box { border: 1px solid #ddd; padding: 12px; min-height: 120px; border-radius: 6px; background: #fff; }
.notes { margin-top: 12px; font-size: 13px; color: #555; }

/* Fim do protótipo */
